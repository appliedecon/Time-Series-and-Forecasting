{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'Mcomp' was built under R version 4.3.3\"\n"
     ]
    }
   ],
   "source": [
    "suppressMessages(library(tidyverse))\n",
    "suppressMessages(library(tsibble))\n",
    "suppressMessages(library(fable))\n",
    "suppressMessages(library(tsibble))\n",
    "suppressMessages(library(fabletools))\n",
    "suppressMessages(library(feasts))\n",
    "suppressMessages(library(lubridate))\n",
    "suppressMessages(library(scales))\n",
    "suppressMessages(library(fpp3))\n",
    "suppressMessages(library(gridExtra))\n",
    "suppressMessages(library(Mcomp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Short Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "m3totsibble <- function(z) {\n",
    "  bind_rows(\n",
    "    as_tsibble(z$x) |> mutate(Type = \"Training\"),\n",
    "    as_tsibble(z$xx) |> mutate(Type = \"Test\")\n",
    "  ) |>\n",
    "    mutate(\n",
    "      st = z$st,\n",
    "      type = z$type,\n",
    "      period = z$period,\n",
    "      description = z$description,\n",
    "      sn = z$sn\n",
    "    ) |>\n",
    "    as_tibble()\n",
    "}\n",
    "\n",
    "short <- Mcomp::M3 |>\n",
    "  subset(\"yearly\") |>\n",
    "  purrr::map_dfr(m3totsibble) |>\n",
    "  group_by(sn) |>\n",
    "  mutate(n = max(row_number())) |>\n",
    "  filter(n <= 20) |>\n",
    "  ungroup() |>\n",
    "  as_tsibble(index = index, key = c(sn, period, st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "short_fit <- short |>\n",
    "  model(arima = ARIMA(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A mdl_df: 10 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>sn</th><th scope=col>period</th><th scope=col>st</th><th scope=col>arima</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;model&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>N0001</td><td>YEARLY</td><td>Y1 </td><td>&lt;ARIMA(1,2,0)&gt;</td></tr>\n",
       "\t<tr><td>N0002</td><td>YEARLY</td><td>Y2 </td><td>&lt;ARIMA(1,0,0) w/ mean&gt;</td></tr>\n",
       "\t<tr><td>N0003</td><td>YEARLY</td><td>Y3 </td><td>&lt;ARIMA(2,0,0) w/ mean&gt;</td></tr>\n",
       "\t<tr><td>N0004</td><td>YEARLY</td><td>Y4 </td><td>&lt;ARIMA(0,1,0)&gt;</td></tr>\n",
       "\t<tr><td>N0005</td><td>YEARLY</td><td>Y5 </td><td>&lt;ARIMA(1,0,0) w/ mean&gt;</td></tr>\n",
       "\t<tr><td>N0006</td><td>YEARLY</td><td>Y6 </td><td>&lt;ARIMA(0,1,0) w/ drift&gt;</td></tr>\n",
       "\t<tr><td>N0007</td><td>YEARLY</td><td>Y7 </td><td>&lt;ARIMA(0,1,0)&gt;</td></tr>\n",
       "\t<tr><td>N0008</td><td>YEARLY</td><td>Y8 </td><td>&lt;ARIMA(0,1,1)&gt;</td></tr>\n",
       "\t<tr><td>N0009</td><td>YEARLY</td><td>Y9 </td><td>&lt;ARIMA(0,1,0) w/ drift&gt;</td></tr>\n",
       "\t<tr><td>N0010</td><td>YEARLY</td><td>Y10</td><td>&lt;ARIMA(2,0,0)&gt;</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A mdl\\_df: 10 × 4\n",
       "\\begin{tabular}{llll}\n",
       " sn & period & st & arima\\\\\n",
       " <chr> & <chr> & <chr> & <model>\\\\\n",
       "\\hline\n",
       "\t N0001 & YEARLY & Y1  & <ARIMA(1,2,0)>\\\\\n",
       "\t N0002 & YEARLY & Y2  & <ARIMA(1,0,0) w/ mean>\\\\\n",
       "\t N0003 & YEARLY & Y3  & <ARIMA(2,0,0) w/ mean>\\\\\n",
       "\t N0004 & YEARLY & Y4  & <ARIMA(0,1,0)>\\\\\n",
       "\t N0005 & YEARLY & Y5  & <ARIMA(1,0,0) w/ mean>\\\\\n",
       "\t N0006 & YEARLY & Y6  & <ARIMA(0,1,0) w/ drift>\\\\\n",
       "\t N0007 & YEARLY & Y7  & <ARIMA(0,1,0)>\\\\\n",
       "\t N0008 & YEARLY & Y8  & <ARIMA(0,1,1)>\\\\\n",
       "\t N0009 & YEARLY & Y9  & <ARIMA(0,1,0) w/ drift>\\\\\n",
       "\t N0010 & YEARLY & Y10 & <ARIMA(2,0,0)>\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A mdl_df: 10 × 4\n",
       "\n",
       "| sn &lt;chr&gt; | period &lt;chr&gt; | st &lt;chr&gt; | arima &lt;model&gt; |\n",
       "|---|---|---|---|\n",
       "| N0001 | YEARLY | Y1  | &lt;ARIMA(1,2,0)&gt; |\n",
       "| N0002 | YEARLY | Y2  | &lt;ARIMA(1,0,0) w/ mean&gt; |\n",
       "| N0003 | YEARLY | Y3  | &lt;ARIMA(2,0,0) w/ mean&gt; |\n",
       "| N0004 | YEARLY | Y4  | &lt;ARIMA(0,1,0)&gt; |\n",
       "| N0005 | YEARLY | Y5  | &lt;ARIMA(1,0,0) w/ mean&gt; |\n",
       "| N0006 | YEARLY | Y6  | &lt;ARIMA(0,1,0) w/ drift&gt; |\n",
       "| N0007 | YEARLY | Y7  | &lt;ARIMA(0,1,0)&gt; |\n",
       "| N0008 | YEARLY | Y8  | &lt;ARIMA(0,1,1)&gt; |\n",
       "| N0009 | YEARLY | Y9  | &lt;ARIMA(0,1,0) w/ drift&gt; |\n",
       "| N0010 | YEARLY | Y10 | &lt;ARIMA(2,0,0)&gt; |\n",
       "\n"
      ],
      "text/plain": [
       "   sn    period st  arima                  \n",
       "1  N0001 YEARLY Y1  <ARIMA(1,2,0)>         \n",
       "2  N0002 YEARLY Y2  <ARIMA(1,0,0) w/ mean> \n",
       "3  N0003 YEARLY Y3  <ARIMA(2,0,0) w/ mean> \n",
       "4  N0004 YEARLY Y4  <ARIMA(0,1,0)>         \n",
       "5  N0005 YEARLY Y5  <ARIMA(1,0,0) w/ mean> \n",
       "6  N0006 YEARLY Y6  <ARIMA(0,1,0) w/ drift>\n",
       "7  N0007 YEARLY Y7  <ARIMA(0,1,0)>         \n",
       "8  N0008 YEARLY Y8  <ARIMA(0,1,1)>         \n",
       "9  N0009 YEARLY Y9  <ARIMA(0,1,0) w/ drift>\n",
       "10 N0010 YEARLY Y10 <ARIMA(2,0,0)>         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "short_fit %>% head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "high_yield_bond_tr <- read.csv('data/BAMLHYH0A0HYM2TRIV.csv')\n",
    "high_yield_bond_tr %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to a tsibble and perform assessment of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "high_yield_bond_tr <- high_yield_bond_tr %>%\n",
    "rename(RETURN_INDEX = BAMLHYH0A0HYM2TRIV) %>%\n",
    "mutate(RETURN_INDEX = as.numeric(RETURN_INDEX)) %>%\n",
    "mutate(DATE = ymd(as.Date(DATE))) %>%\n",
    "as_tsibble(index=DATE)\n",
    "\n",
    "high_yield_bond_tr %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "high_yield_bond_tr %>%\n",
    "filter(is.na(RETURN_INDEX)) %>%\n",
    "head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implicit Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "high_yield_bond_tr %>% scan_gaps() %>% head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "high_yield_bond_tr <- high_yield_bond_tr %>%\n",
    "fill_gaps()\n",
    "\n",
    "high_yield_bond_tr %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding and Filling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Weekly Data\n",
    "- Difficult to work with since seasonal period is large and non-integer.  \n",
    "- Most years have 52 weeks, but there is the occasional 53 weeks.\n",
    "- Starts on a different day each year.\n",
    "- Weeks will start on different days.\n",
    "- Simplest approach is using STL decomposition then a non-seasonal method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "my_dcmp_spec <- decomposition_model(\n",
    "  STL(Barrels),\n",
    "  ETS(season_adjust ~ season(\"N\"))\n",
    ")\n",
    "\n",
    "us_gasoline |>\n",
    "  model(stl_ets = my_dcmp_spec) |>\n",
    "  forecast(h = \"2 years\") |>\n",
    "  autoplot(us_gasoline) +\n",
    "  labs(y = \"Millions of barrels per day\",\n",
    "       title = \"Weekly US gasoline production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, harmonic regression can be used\n",
    "Finding `K` can be computationally expensive though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gas_dhr <- us_gasoline |>\n",
    "  model(dhr = ARIMA(Barrels ~ PDQ(0, 0, 0) + fourier(K = 6)))\n",
    "gas_dhr |>\n",
    "  forecast(h = \"2 years\") |>\n",
    "  autoplot(us_gasoline) +\n",
    "  labs(y = \"Millions of barrels per day\",\n",
    "       title = \"Weekly US gasoline production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- STL is better if the seasonality is changing over time.  \n",
    "- Harmonic will be better if you have additional regressors to include."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily and Sub-Daily\n",
    "- Multiple seasonal periods  \n",
    "- If time series is short there may be only one seasonal pattern  \n",
    "- If long enough use STL, harmonic regression, or Prophet.  \n",
    "- Seasonality with moving holidays will be more challenging, those will need to be handled with dummmy variables using ARIMA or Prophet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Counts\n",
    "- Discussed models assume the data is continuous.  \n",
    "- Often data is of counts, e.g., number of products sold, number of people, and the result could only be integers.  \n",
    "- Generally doesn't matter if the counts are somewhat large, e.g., above 100.  \n",
    "- For smaller counts, assuming the data is continuous could have implications on forecasting performance.  \n",
    "- Also need to constrain the forecasts to be positive, i.e., cannot have negative people.\n",
    "- A method is `Croston's method`, which is really an approximation of count data rather than explicitly a method for handling count data.\n",
    "\n",
    "Croston's Method:\n",
    "- Construct two new series $\\alpha$ and $q$, where $q_i$ is the ***i***th quantity of non-zero counts and $\\alpha_i$ is the time between $q_i$ and $q_{i+1}$.  \n",
    "- Separate exponential smoothing forecasts for each new series.  \n",
    "- Usually applied to timing of demand and demand for items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "j06 <- PBS |>\n",
    "  filter(ATC2 == \"J06\") |>\n",
    "  summarise(Scripts = sum(Scripts))\n",
    "\n",
    "j06 |> autoplot(Scripts) +\n",
    "  labs(y=\"Number of scripts\",\n",
    "       title = \"Sales for immune sera and immunoglobulins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "j06_croston <- j06 |>\n",
    "  model(CROSTON(Scripts))\n",
    "\n",
    "j06_croston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "j06_croston %>% forecast(h=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraining Forecasts to a Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "egg_prices <- prices |> filter(!is.na(eggs))\n",
    "egg_prices |>\n",
    "  model(ETS(eggs ~ trend(\"A\"))) |>\n",
    "  forecast(h = 50) |>\n",
    "  autoplot(egg_prices) +\n",
    "  geom_hline(yintercept = 0) +\n",
    "  ylim(-100, 400) +\n",
    "  labs(title = \"Annual egg prices (Modeling Egg Price)\",\n",
    "       y = \"$US (in cents adjusted for inflation) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model the log to avoid the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "egg_prices <- prices |> filter(!is.na(eggs))\n",
    "egg_prices |>\n",
    "  model(ETS(log(eggs) ~ trend(\"A\"))) |>\n",
    "  forecast(h = 50) |>\n",
    "  autoplot(egg_prices) +\n",
    "  geom_hline(yintercept = 0) +\n",
    "  ylim(-100, 400) +\n",
    "  labs(title = \"Annual egg prices (Modeling Log(Egg Price))\",\n",
    "       y = \"$US (in cents adjusted for inflation) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To constrain, need a custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "scaled_logit <- function(x, lower = 0, upper = 1) {\n",
    "  log((x - lower) / (upper - x))\n",
    "}\n",
    "inv_scaled_logit <- function(x, lower = 0, upper = 1) {\n",
    "  (upper - lower) * exp(x) / (1 + exp(x)) + lower\n",
    "}\n",
    "my_scaled_logit <- new_transformation(\n",
    "                    scaled_logit, inv_scaled_logit)\n",
    "egg_prices |>\n",
    "  model(\n",
    "    ETS(my_scaled_logit(eggs, lower = 50, upper = 400)\n",
    "          ~ trend(\"A\"))\n",
    "  ) |>\n",
    "  forecast(h = 50) |>\n",
    "  autoplot(egg_prices) +\n",
    "  geom_hline(yintercept = 0) +\n",
    "  ylim(-100, 400) +\n",
    "  labs(title = \"Annual egg prices\",\n",
    "       y = \"$US (in cents adjusted for inflation) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual CUSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(1243)\n",
    "white_noise <- rnorm(120) %>% ts(start=c(2000,1), frequency = 12)\n",
    "white_noise %>% as_tsibble() %>% ACF() %>% autoplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "qqplot(trend, white_noise,conf.level = .95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "qqnorm(white_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "trend <- 1:120\n",
    "\n",
    "white_noise_sc <- strucchange::efp(white_noise ~ trend, type='Rec-CUSUM')\n",
    "white_noise_sc %>% plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Intervals for Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
